{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ba2UrRNoD_y1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 16:22:26.716136: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:26.716152: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/ej/workspace/hls4ml/hls4ml/hls4ml/converters/__init__.py:15: UserWarning: WARNING: Pytorch converter is not enabled!\n",
      "  warnings.warn(\"WARNING: Pytorch converter is not enabled!\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import hls4ml\n",
    "import os\n",
    "os.environ['PATH'] = '/opt/Xilinx/Vivado/2019.2/bin:' + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Q7KKAw-IEZnB"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def readucr(filename):\n",
    "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
    "    y = data[:, 0]\n",
    "    x = data[:, 1:]\n",
    "    return x, y.astype(int)\n",
    "\n",
    "\n",
    "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
    "\n",
    "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
    "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
    "\n",
    "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
    "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "x_train = x_train[:,:100:2]\n",
    "x_test = x_test[:,:100:2]\n",
    "\n",
    "\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "idx = np.random.permutation(len(x_train))\n",
    "x_train = x_train[idx]\n",
    "y_train = y_train[idx]\n",
    "\n",
    "y_train[y_train == -1] = 0\n",
    "y_test[y_test == -1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-20 16:22:27.973492: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-20 16:22:27.973929: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.973975: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.974015: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.974053: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.974089: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.974124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.974160: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.974195: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2023-04-20 16:22:27.974201: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-04-20 16:22:27.974374: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('timeseries_3b_l50.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50, 1)]      0           []                               \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 50, 1)       337         ['input_1[0][0]',                \n",
      " dAttention)                                                      'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 50, 1)        0           ['multi_head_attention[0][0]']   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 50, 4)        8           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50, 4)        0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 50, 1)        5           ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 50, 1)        0           ['dropout[0][0]',                \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 50, 1)        0           ['dense_1[0][0]',                \n",
      "                                                                  'add[0][0]']                    \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (MultiH  (None, 50, 1)       337         ['add_1[0][0]',                  \n",
      " eadAttention)                                                    'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 50, 1)        0           ['multi_head_attention_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 50, 4)        8           ['dropout_2[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 50, 4)        0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 50, 1)        5           ['dropout_3[0][0]']              \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 50, 1)        0           ['dropout_2[0][0]',              \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 50, 1)        0           ['dense_3[0][0]',                \n",
      "                                                                  'add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (MultiH  (None, 50, 1)       337         ['add_3[0][0]',                  \n",
      " eadAttention)                                                    'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 50, 1)        0           ['multi_head_attention_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 50, 4)        8           ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 50, 4)        0           ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 50, 1)        5           ['dropout_5[0][0]']              \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 50, 1)        0           ['dropout_4[0][0]',              \n",
      "                                                                  'add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 50, 1)        0           ['dense_5[0][0]',                \n",
      "                                                                  'add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 50)           0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 32)           1632        ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 32)           0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 16)           528         ['dropout_6[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 16)           0           ['dense_7[0][0]']                \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 2)            34          ['dropout_7[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,244\n",
      "Trainable params: 3,244\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "x_test1=np.ascontiguousarray(x_test[100:200,:,:])\n",
    "y_keras = model.predict(x_test1)\n",
    "y_test_binary = np.where(y_keras > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<8,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<8,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<8,6>', 'scale': 'ap_fixed<8,6>', 'bias': 'ap_fixed<8,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<10,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<10,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,6>', 'scale': 'ap_fixed<10,6>', 'bias': 'ap_fixed<10,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<12,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<12,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,6>', 'scale': 'ap_fixed<12,6>', 'bias': 'ap_fixed<12,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<14,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<14,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,6>', 'scale': 'ap_fixed<14,6>', 'bias': 'ap_fixed<14,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<16,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<16,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,6>', 'scale': 'ap_fixed<16,6>', 'bias': 'ap_fixed<16,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<18,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<18,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,6>', 'scale': 'ap_fixed<18,6>', 'bias': 'ap_fixed<18,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<20,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<20,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,6>', 'scale': 'ap_fixed<20,6>', 'bias': 'ap_fixed<20,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<22,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<22,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,6>', 'scale': 'ap_fixed<22,6>', 'bias': 'ap_fixed<22,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<24,6>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<24,6>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,6>', 'scale': 'ap_fixed<24,6>', 'bias': 'ap_fixed<24,6>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "auc_arr = np.array([])\n",
    "int_bit = 6\n",
    "for i in range(2, 19, 2):\n",
    "    precision = 'ap_fixed<{},{}>'.format((int_bit+i), int_bit)\n",
    "    dirc = 'CE_precision/{}int_{}frac'.format(int_bit, i)\n",
    "    #First, the baseline model\n",
    "    hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "    # Set the precision and reuse factor for the full model\n",
    "    hls_config['Model']['Precision'] = precision\n",
    "    hls_config['Model']['ReuseFactor'] = 1\n",
    "    hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "    for Layer in hls_config['LayerName'].keys():\n",
    "        hls_config['LayerName'][Layer]['Precision'] = precision\n",
    "        hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "        hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        hls_config['LayerName'][Layer]['weight'] = precision\n",
    "        hls_config['LayerName'][Layer]['scale'] = precision\n",
    "        hls_config['LayerName'][Layer]['bias'] = precision\n",
    "        hls_config['LayerName'][Layer]['accum_t'] = 'ap_fixed<22,10>'\n",
    "        if 'multi_head_attention' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "        if 'dense' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "    print(hls_config)\n",
    "\n",
    "    cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "    cfg['IOType']     = 'io_parallel' \n",
    "    cfg['HLSConfig']  = hls_config\n",
    "    cfg['KerasModel'] = model\n",
    "    cfg['OutputDir']  = dirc\n",
    "    cfg['Part'] = 'xcvu13p-fhga2104-2L-e'\n",
    "\n",
    "    hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "    hls_model.compile()\n",
    "    y_hls = hls_model.predict(np.ascontiguousarray(x_test1, dtype=np.float32))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_binary.ravel(), y_hls.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_arr = np.append(auc_arr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52975 0.6769  0.5251  0.9718  0.99765 0.99785 0.997   0.99655 0.99625]\n"
     ]
    }
   ],
   "source": [
    "print(auc_arr)\n",
    "int6 = auc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<9,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<9,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<9,7>', 'scale': 'ap_fixed<9,7>', 'bias': 'ap_fixed<9,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<11,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<11,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,7>', 'scale': 'ap_fixed<11,7>', 'bias': 'ap_fixed<11,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<13,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<13,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,7>', 'scale': 'ap_fixed<13,7>', 'bias': 'ap_fixed<13,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<15,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<15,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,7>', 'scale': 'ap_fixed<15,7>', 'bias': 'ap_fixed<15,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<17,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<17,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,7>', 'scale': 'ap_fixed<17,7>', 'bias': 'ap_fixed<17,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<19,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<19,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,7>', 'scale': 'ap_fixed<19,7>', 'bias': 'ap_fixed<19,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<21,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<21,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,7>', 'scale': 'ap_fixed<21,7>', 'bias': 'ap_fixed<21,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<23,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<23,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,7>', 'scale': 'ap_fixed<23,7>', 'bias': 'ap_fixed<23,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<25,7>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<25,7>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,7>', 'scale': 'ap_fixed<25,7>', 'bias': 'ap_fixed<25,7>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "auc_arr = np.array([])\n",
    "int_bit = 7\n",
    "for i in range(2, 19, 2):\n",
    "    precision = 'ap_fixed<{},{}>'.format((int_bit+i), int_bit)\n",
    "    dirc = 'CE_precision/{}int_{}frac'.format(int_bit, i)\n",
    "    #First, the baseline model\n",
    "    hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "    # Set the precision and reuse factor for the full model\n",
    "    hls_config['Model']['Precision'] = precision\n",
    "    hls_config['Model']['ReuseFactor'] = 1\n",
    "    hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "    for Layer in hls_config['LayerName'].keys():\n",
    "        hls_config['LayerName'][Layer]['Precision'] = precision\n",
    "        hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "        hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        hls_config['LayerName'][Layer]['weight'] = precision\n",
    "        hls_config['LayerName'][Layer]['scale'] = precision\n",
    "        hls_config['LayerName'][Layer]['bias'] = precision\n",
    "        hls_config['LayerName'][Layer]['accum_t'] = 'ap_fixed<22,10>'\n",
    "        if 'multi_head_attention' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "        if 'dense' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "    print(hls_config)\n",
    "\n",
    "    cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "    cfg['IOType']     = 'io_parallel' \n",
    "    cfg['HLSConfig']  = hls_config\n",
    "    cfg['KerasModel'] = model\n",
    "    cfg['OutputDir']  = dirc\n",
    "    cfg['Part'] = 'xcvu13p-fhga2104-2L-e'\n",
    "\n",
    "    hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "    hls_model.compile()\n",
    "    y_hls = hls_model.predict(np.ascontiguousarray(x_test1, dtype=np.float32))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_binary.ravel(), y_hls.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_arr = np.append(auc_arr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52975 0.6769  0.5251  0.9718  0.99765 0.99785 0.997   0.99655 0.99625]\n"
     ]
    }
   ],
   "source": [
    "print(auc_arr)\n",
    "int7 = auc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<10,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<10,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<10,8>', 'scale': 'ap_fixed<10,8>', 'bias': 'ap_fixed<10,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<12,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<12,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,8>', 'scale': 'ap_fixed<12,8>', 'bias': 'ap_fixed<12,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<14,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<14,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,8>', 'scale': 'ap_fixed<14,8>', 'bias': 'ap_fixed<14,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<16,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<16,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,8>', 'scale': 'ap_fixed<16,8>', 'bias': 'ap_fixed<16,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<18,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,8>', 'scale': 'ap_fixed<18,8>', 'bias': 'ap_fixed<18,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<20,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<20,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,8>', 'scale': 'ap_fixed<20,8>', 'bias': 'ap_fixed<20,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<22,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<22,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,8>', 'scale': 'ap_fixed<22,8>', 'bias': 'ap_fixed<22,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<24,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<24,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,8>', 'scale': 'ap_fixed<24,8>', 'bias': 'ap_fixed<24,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<26,8>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<26,8>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,8>', 'scale': 'ap_fixed<26,8>', 'bias': 'ap_fixed<26,8>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "auc_arr = np.array([])\n",
    "int_bit = 8\n",
    "for i in range(2, 19, 2):\n",
    "    precision = 'ap_fixed<{},{}>'.format((int_bit+i), int_bit)\n",
    "    dirc = 'CE_precision/{}int_{}frac'.format(int_bit, i)\n",
    "    #First, the baseline model\n",
    "    hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "    # Set the precision and reuse factor for the full model\n",
    "    hls_config['Model']['Precision'] = precision\n",
    "    hls_config['Model']['ReuseFactor'] = 1\n",
    "    hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "    for Layer in hls_config['LayerName'].keys():\n",
    "        hls_config['LayerName'][Layer]['Precision'] = precision\n",
    "        hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "        hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        hls_config['LayerName'][Layer]['weight'] = precision\n",
    "        hls_config['LayerName'][Layer]['scale'] = precision\n",
    "        hls_config['LayerName'][Layer]['bias'] = precision\n",
    "        hls_config['LayerName'][Layer]['accum_t'] = 'ap_fixed<22,10>'\n",
    "        if 'multi_head_attention' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "        if 'dense' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "    print(hls_config)\n",
    "\n",
    "    cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "    cfg['IOType']     = 'io_parallel' \n",
    "    cfg['HLSConfig']  = hls_config\n",
    "    cfg['KerasModel'] = model\n",
    "    cfg['OutputDir']  = dirc\n",
    "    cfg['Part'] = 'xcvu13p-fhga2104-2L-e'\n",
    "\n",
    "    hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "    hls_model.compile()\n",
    "    y_hls = hls_model.predict(np.ascontiguousarray(x_test1, dtype=np.float32))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_binary.ravel(), y_hls.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_arr = np.append(auc_arr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52975 0.6769  0.5251  0.9718  0.99765 0.99785 0.997   0.99655 0.99625]\n"
     ]
    }
   ],
   "source": [
    "print(auc_arr)\n",
    "int8 = auc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<11,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<11,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<11,9>', 'scale': 'ap_fixed<11,9>', 'bias': 'ap_fixed<11,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<13,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<13,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<13,9>', 'scale': 'ap_fixed<13,9>', 'bias': 'ap_fixed<13,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<15,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<15,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<15,9>', 'scale': 'ap_fixed<15,9>', 'bias': 'ap_fixed<15,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<17,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<17,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<17,9>', 'scale': 'ap_fixed<17,9>', 'bias': 'ap_fixed<17,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<19,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<19,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<19,9>', 'scale': 'ap_fixed<19,9>', 'bias': 'ap_fixed<19,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<21,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<21,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<21,9>', 'scale': 'ap_fixed<21,9>', 'bias': 'ap_fixed<21,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<23,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<23,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<23,9>', 'scale': 'ap_fixed<23,9>', 'bias': 'ap_fixed<23,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<25,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<25,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<25,9>', 'scale': 'ap_fixed<25,9>', 'bias': 'ap_fixed<25,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<27,9>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<27,9>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<27,9>', 'scale': 'ap_fixed<27,9>', 'bias': 'ap_fixed<27,9>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "auc_arr = np.array([])\n",
    "int_bit = 9\n",
    "for i in range(2, 19, 2):\n",
    "    precision = 'ap_fixed<{},{}>'.format((int_bit+i), int_bit)\n",
    "    dirc = 'CE_precision/{}int_{}frac'.format(int_bit, i)\n",
    "    #First, the baseline model\n",
    "    hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "    # Set the precision and reuse factor for the full model\n",
    "    hls_config['Model']['Precision'] = precision\n",
    "    hls_config['Model']['ReuseFactor'] = 1\n",
    "    hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "    for Layer in hls_config['LayerName'].keys():\n",
    "        hls_config['LayerName'][Layer]['Precision'] = precision\n",
    "        hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "        hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        hls_config['LayerName'][Layer]['weight'] = precision\n",
    "        hls_config['LayerName'][Layer]['scale'] = precision\n",
    "        hls_config['LayerName'][Layer]['bias'] = precision\n",
    "        hls_config['LayerName'][Layer]['accum_t'] = 'ap_fixed<22,10>'\n",
    "        if 'multi_head_attention' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "        if 'dense' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "    print(hls_config)\n",
    "\n",
    "    cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "    cfg['IOType']     = 'io_parallel' \n",
    "    cfg['HLSConfig']  = hls_config\n",
    "    cfg['KerasModel'] = model\n",
    "    cfg['OutputDir']  = dirc\n",
    "    cfg['Part'] = 'xcvu13p-fhga2104-2L-e'\n",
    "\n",
    "    hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "    hls_model.compile()\n",
    "    y_hls = hls_model.predict(np.ascontiguousarray(x_test1, dtype=np.float32))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_binary.ravel(), y_hls.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_arr = np.append(auc_arr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52975 0.6769  0.5251  0.9718  0.99765 0.99785 0.997   0.99655 0.99625]\n"
     ]
    }
   ],
   "source": [
    "print(auc_arr)\n",
    "int9 = auc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<12,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<12,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<12,10>', 'scale': 'ap_fixed<12,10>', 'bias': 'ap_fixed<12,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<14,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<14,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<14,10>', 'scale': 'ap_fixed<14,10>', 'bias': 'ap_fixed<14,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<16,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<16,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<16,10>', 'scale': 'ap_fixed<16,10>', 'bias': 'ap_fixed<16,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<18,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<18,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<18,10>', 'scale': 'ap_fixed<18,10>', 'bias': 'ap_fixed<18,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<20,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<20,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<20,10>', 'scale': 'ap_fixed<20,10>', 'bias': 'ap_fixed<20,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<22,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<22,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<22,10>', 'scale': 'ap_fixed<22,10>', 'bias': 'ap_fixed<22,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<24,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<24,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<24,10>', 'scale': 'ap_fixed<24,10>', 'bias': 'ap_fixed<24,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<26,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<26,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<26,10>', 'scale': 'ap_fixed<26,10>', 'bias': 'ap_fixed<26,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: Input\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention\n",
      "Layer name: dense, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense\n",
      "Layer name: dense_1, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_1\n",
      "Layer name: add, layer type: Add\n",
      "Layer name: add_1, layer type: Add\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention\n",
      "Layer name: dense_2, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_2\n",
      "Layer name: dense_3, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_3\n",
      "Layer name: add_2, layer type: Add\n",
      "Layer name: add_3, layer type: Add\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention\n",
      "Layer name: dense_4, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_4\n",
      "Layer name: dense_5, layer type: Dense\n",
      "  -> Activation (linear), layer name: dense_5\n",
      "Layer name: add_4, layer type: Add\n",
      "Layer name: add_5, layer type: Add\n",
      "Layer name: dense_6, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_6\n",
      "Layer name: dense_7, layer type: Dense\n",
      "  -> Activation (relu), layer name: dense_7\n",
      "Layer name: dense_8, layer type: Dense\n",
      "  -> Activation (softmax), layer name: dense_8\n",
      "{'Model': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource'}, 'LayerName': {'input_1': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_relu': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_1': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_1_linear': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_1': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_1': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_2': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_2_relu': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_3': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_3_linear': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_2': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_3': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>'}, 'multi_head_attention_2': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4, 'table_size': 1024}, 'dense_4': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_4_relu': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_5': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_5_linear': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'add_4': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>'}, 'add_5': {'Precision': 'ap_fixed<28,10>', 'Strategy': 'Resource', 'ReuseFactor': 1, 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>'}, 'dense_6': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_6_relu': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_7': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_7_relu': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}, 'dense_8': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'table_size': 1024, 'exp_range': 4}, 'dense_8_softmax': {'Precision': 'ap_fixed<28,10>', 'ReuseFactor': 1, 'table_size': 1024, 'table_t': 'ap_fixed<18,8>', 'Strategy': 'Resource', 'weight': 'ap_fixed<28,10>', 'scale': 'ap_fixed<28,10>', 'bias': 'ap_fixed<28,10>', 'accum_t': 'ap_fixed<22,10>', 'inv_range': 256, 'exp_range': 4}}}\n",
      "Interpreting Model\n",
      "Topology:\n",
      "Layer name: input_1, layer type: InputLayer, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_1, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_1, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_1, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_2, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_3, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_2, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_3, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: multi_head_attention_2, layer type: MultiHeadAttention, input shapes: [[None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: dense_4, layer type: Dense, input shapes: [[None, 50, 1]], output shape: [None, 50, 4]\n",
      "Layer name: dense_5, layer type: Dense, input shapes: [[None, 50, 4]], output shape: [None, 50, 1]\n",
      "Layer name: add_4, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: add_5, layer type: Merge, input shapes: [[None, 50, 1], [None, 50, 1]], output shape: [None, 50, 1]\n",
      "Layer name: flatten, layer type: Reshape, input shapes: [[None, 50, 1]], output shape: [None, 50]\n",
      "Layer name: dense_6, layer type: Dense, input shapes: [[None, 50]], output shape: [None, 32]\n",
      "Layer name: dense_7, layer type: Dense, input shapes: [[None, 32]], output shape: [None, 16]\n",
      "Layer name: dense_8, layer type: Dense, input shapes: [[None, 16]], output shape: [None, 2]\n",
      "Creating HLS model\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"input_1\" (Input)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_1_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_1\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_1\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_2_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_3_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_2\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_3\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"multi_head_attention_2\" (MultiHeadAttention)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_4_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_5_linear\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_4\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"add_5\" (Merge)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_6_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_7_relu\" (Activation)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8\" (Dense)\n",
      "WARNING: Config parameter \"accum_t\" overwrites an existing attribute in layer \"dense_8_softmax\" (Softmax)\n",
      "not transpose\n",
      "not transpose\n",
      "not transpose\n",
      "Writing HLS project\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "auc_arr = np.array([])\n",
    "int_bit = 10\n",
    "for i in range(2, 19, 2):\n",
    "    precision = 'ap_fixed<{},{}>'.format((int_bit+i), int_bit)\n",
    "    dirc = 'CE_precision/{}int_{}frac'.format(int_bit, i)\n",
    "    #First, the baseline model\n",
    "    hls_config = hls4ml.utils.config_from_keras_model(model, granularity='name')\n",
    "\n",
    "    # Set the precision and reuse factor for the full model\n",
    "    hls_config['Model']['Precision'] = precision\n",
    "    hls_config['Model']['ReuseFactor'] = 1\n",
    "    hls_config['Model']['Strategy'] = 'Resource'\n",
    "\n",
    "    for Layer in hls_config['LayerName'].keys():\n",
    "        hls_config['LayerName'][Layer]['Precision'] = precision\n",
    "        hls_config['LayerName'][Layer]['Strategy'] = 'Resource'\n",
    "        hls_config['LayerName'][Layer]['ReuseFactor'] = 1\n",
    "        hls_config['LayerName'][Layer]['weight'] = precision\n",
    "        hls_config['LayerName'][Layer]['scale'] = precision\n",
    "        hls_config['LayerName'][Layer]['bias'] = precision\n",
    "        hls_config['LayerName'][Layer]['accum_t'] = 'ap_fixed<22,10>'\n",
    "        if 'multi_head_attention' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "        if 'dense' in Layer:\n",
    "            hls_config['LayerName'][Layer]['inv_range'] = 256\n",
    "            hls_config['LayerName'][Layer]['table_size'] = 1024\n",
    "            hls_config['LayerName'][Layer]['exp_range'] = 4\n",
    "    print(hls_config)\n",
    "\n",
    "    cfg = hls4ml.converters.create_config(backend='Vivado')\n",
    "    cfg['IOType']     = 'io_parallel' \n",
    "    cfg['HLSConfig']  = hls_config\n",
    "    cfg['KerasModel'] = model\n",
    "    cfg['OutputDir']  = dirc\n",
    "    cfg['Part'] = 'xcvu13p-fhga2104-2L-e'\n",
    "\n",
    "    hls_model = hls4ml.converters.keras_to_hls(cfg)\n",
    "    hls_model.compile()\n",
    "    y_hls = hls_model.predict(np.ascontiguousarray(x_test1, dtype=np.float32))\n",
    "    fpr, tpr, thresholds = roc_curve(y_test_binary.ravel(), y_hls.ravel())\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    auc_arr = np.append(auc_arr, roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.52975 0.6769  0.5251  0.9718  0.99765 0.99785 0.997   0.99655 0.99625]\n"
     ]
    }
   ],
   "source": [
    "print(auc_arr)\n",
    "int10 = auc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "x_axis = [2,4,6,8,10,12,14,16,18]\n",
    "ax.plot(x_axis, int6, \"-o\", label = \"6 int\")\n",
    "ax.plot(x_axis, int7, \"-o\", label = '7 int')\n",
    "ax.plot(x_axis, int8, \"-o\", label = '8 int')\n",
    "ax.plot(x_axis, int9, \"-o\", label = '9 int')\n",
    "ax.plot(x_axis, int10, \"-o\", label = '10 int')\n",
    "\n",
    "ax.legend(loc='lower right')\n",
    "ax.set_xlabel(\"fractional bits\")\n",
    "ax.set_ylabel(\"AUC\")\n",
    "\n",
    "# Set the title and adjust its position \n",
    "ax.set_title(\"Engine Anormaly Detection\", loc='left', fontweight='bold', pad=20)\n",
    "\n",
    "ax.grid()\n",
    "ax.set_ylim([0.0, 1.03])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "transformer_gpu",
   "language": "python",
   "name": "transformer_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
